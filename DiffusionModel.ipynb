{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JEq34uFRq4c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetBlock(tf.keras.layers.Layer):\n",
        "  def __init__(self, filters, kernel_size):\n",
        "    super(ResNetBlock, self).__init__()\n",
        "    self.conv2d = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
        "    self.group_norm = tf.keras.layers.GroupNormalization(axis=-1)\n",
        "    self.gelu = tf.keras.layers.Activation('gelu')\n",
        "    self.conv2d_2 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
        "    self.group_norm_2 = tf.keras.layers.GroupNormalization(axis=-1)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.conv2d(inputs)\n",
        "    x = self.group_norm(x)\n",
        "    x = self.gelu(x)\n",
        "    x = self.conv2d_2(x)\n",
        "    x = self.group_norm_2(x)\n",
        "\n",
        "    return tf.keras.layers.Add()([inputs, x])\n"
      ],
      "metadata": {
        "id": "VZIvK6qLRvl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownSampleBlock(tf.keras.layers.Layer):\n",
        "  def __init__(self, filters, kernel_size):\n",
        "    super(DownSampleBlock, self).__init__()\n",
        "    self.max_pool = tf.keras.layers.MaxPool2D((2, 2))\n",
        "    self.resnet_block = ResNetBlock(filters, kernel_size)\n",
        "    self.resnet_block_2 = ResNetBlock(filters, kernel_size)\n",
        "    self.linear = tf.keras.layers.Dense(filters)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x, y = inputs\n",
        "    x = self.max_pool(x)\n",
        "    x = self.resnet_block(x)\n",
        "    x = self.resnet_block_2(x)\n",
        "    y = tf.keras.activations.silu(y)\n",
        "    y = self.linear(y)\n",
        "\n",
        "    return x + y"
      ],
      "metadata": {
        "id": "Dar7upXUVDnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttentionBlock(tf.keras.layers.Layer):\n",
        "  def __init__(self, filters):\n",
        "    super(SelfAttentionBlock, self).__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.linear1 = tf.keras.layers.Dense(filters)\n",
        "    self.gelu = tf.keras.layers.Activation('gelu')\n",
        "    self.linear2 = tf.keras.layers.Dense(filters)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = tf.reshape(inputs, shape=(inputs.shape[0], -1, inputs.shape[-1]))  # Shape: (128, 1024)\n",
        "    x = tf.transpose(x, perm=[1, 0, 2])\n",
        "\n",
        "    x_norm = self.layernorm1(x)\n",
        "    x_mha = self.mha(query=x_norm, key=x_norm, value=x_norm)\n",
        "\n",
        "    x_mha_out = x_mha + x\n",
        "    x_mha_out = self.layernorm2(x_mha_out)\n",
        "\n",
        "    x_ffn = self.linear1(x_mha_out)\n",
        "    x_ffn = self.gelu(x_ffn)\n",
        "    x_ffn = self.linear2(x_ffn)\n",
        "\n",
        "    x_out = x_ffn + x_mha_out\n",
        "    x_out = tf.transpose(x_out, perm=[1, 0, 2])  # Shape back to (128, 1024)\n",
        "    x_out = tf.reshape(x_out, shape=inputs.shape)\n",
        "\n",
        "    return x_out"
      ],
      "metadata": {
        "id": "i-kSon3UXfTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpsampleBlock(tf.keras.layers.Layer):\n",
        "  def __init__(self, filters, kernel_size):\n",
        "    super(UpsampleBlock, self).__init__()\n",
        "    self.resnet_block = ResNetBlock(filters, kernel_size)\n",
        "    self.resnet_block_2 = ResNetBlock(filters, kernel_size)\n",
        "    self.linear = tf.keras.layers.Dense(filters)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x, y, z = inputs\n",
        "    x_concat = tf.concat([x, y], axis=-1)\n",
        "\n",
        "    x_resnet_1 = self.resnet_block(x_concat)\n",
        "    x_resnet_2 = self.resnet_block_2(x_resnet_1)\n",
        "\n",
        "    z_silu = tf.keras.activations.silu(z)\n",
        "    z_linear = self.linear(z_silu)\n",
        "\n",
        "    return x_resnet_2 + z_linear"
      ],
      "metadata": {
        "id": "oJmlKwd0aOer"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}