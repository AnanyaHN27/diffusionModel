{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "id": "_JEq34uFRq4c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, dim):\n",
        "        super(TimeEmbedding, self).__init__()\n",
        "        self.dim = dim\n",
        "        self.half_dim = dim // 2\n",
        "        self.emb = tf.math.log(10000.0) / (self.half_dim - 1)\n",
        "        self.emb = tf.exp(tf.range(self.half_dim, dtype=tf.float32) * -self.emb)\n",
        "\n",
        "    def call(self, timesteps):\n",
        "        timesteps = tf.cast(timesteps, tf.float32)\n",
        "        emb = timesteps[:, None] * self.emb[None, :]\n",
        "        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=-1)\n",
        "        return emb"
      ],
      "metadata": {
        "id": "p-jmxXZ5lzfj"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        self.conv2d = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
        "        self.group_norm = tf.keras.layers.GroupNormalization(axis=-1)\n",
        "        self.gelu = tf.keras.layers.Activation('gelu')\n",
        "        self.conv2d_2 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
        "        self.group_norm_2 = tf.keras.layers.GroupNormalization(axis=-1)\n",
        "        self.adjust_dim = tf.keras.layers.Conv2D(filters, 1, padding='same')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if tf.rank(inputs) == 3:\n",
        "          inputs = tf.expand_dims(inputs, axis=1)\n",
        "        x = self.conv2d(inputs)\n",
        "        x = self.group_norm(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.conv2d_2(x)\n",
        "        x = self.group_norm_2(x)\n",
        "\n",
        "        inputs = self.adjust_dim(inputs)\n",
        "\n",
        "        return tf.keras.layers.Add()([inputs, x])"
      ],
      "metadata": {
        "id": "VZIvK6qLRvl7"
      },
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownSampleBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size):\n",
        "        super(DownSampleBlock, self).__init__()\n",
        "        self.max_pool = tf.keras.layers.MaxPool2D((2, 2))\n",
        "        self.resnet_block = ResNetBlock(filters, kernel_size)\n",
        "        self.resnet_block_2 = ResNetBlock(filters, kernel_size)\n",
        "        self.linear = tf.keras.layers.Dense(filters)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, y = inputs\n",
        "        x = self.max_pool(x)\n",
        "        x = self.resnet_block(x)\n",
        "        x = self.resnet_block_2(x)\n",
        "\n",
        "        y = tf.keras.activations.silu(y)\n",
        "        y = self.linear(y)\n",
        "        y = tf.reshape(y, [y.shape[0], 1, 1, y.shape[-1]])\n",
        "\n",
        "        return x + y"
      ],
      "metadata": {
        "id": "Dar7upXUVDnv"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttentionBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, num_heads=8, embed_dim=64):\n",
        "        super(SelfAttentionBlock, self).__init__()\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.linear1 = tf.keras.layers.Dense(filters)\n",
        "        self.gelu = tf.keras.layers.Activation('gelu')\n",
        "        self.linear2 = tf.keras.layers.Dense(filters)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = tf.reshape(inputs, shape=(inputs.shape[0], -1, inputs.shape[-1]))\n",
        "        x_norm = self.layernorm1(x)\n",
        "        x_mha = self.mha(query=x_norm, key=x_norm, value=x_norm)\n",
        "        x_mha_out = x_mha + x\n",
        "        x_mha_out = self.layernorm2(x_mha_out)\n",
        "        x_ffn = self.linear1(x_mha_out)\n",
        "        x_ffn = self.gelu(x_ffn)\n",
        "        x_ffn = self.linear2(x_ffn)\n",
        "        return x_ffn + x_mha_out"
      ],
      "metadata": {
        "id": "i-kSon3UXfTR"
      },
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpsampleBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size):\n",
        "        super(UpsampleBlock, self).__init__()\n",
        "        self.upsample = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation='nearest')\n",
        "        self.resnet_block = ResNetBlock(filters, kernel_size)\n",
        "        self.resnet_block_2 = ResNetBlock(filters, kernel_size)\n",
        "        self.linear = tf.keras.layers.Dense(filters)\n",
        "        self.reduce_skip = tf.keras.layers.Conv2D(filters, 1, padding='same')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, skip, t = inputs\n",
        "\n",
        "        # Upsample x\n",
        "        x = self.upsample(x)\n",
        "\n",
        "        # Ensure skip has the right shape\n",
        "        skip = self.reduce_skip(skip)\n",
        "\n",
        "        # Check the shapes for debugging\n",
        "        print(f\"x shape after upsampling: {x.shape}\")\n",
        "        print(f\"skip shape after reduction: {skip.shape}\")\n",
        "\n",
        "        # Concatenate x and skip\n",
        "        if skip.shape[1] != x.shape[1] or skip.shape[2] != x.shape[2]:\n",
        "            skip = tf.image.resize(skip, [x.shape[1], x.shape[2]])\n",
        "        print(f\"After resizing skip shape: {skip.shape}\")\n",
        "\n",
        "        x = tf.image.resize(x, [skip.shape[1], skip.shape[2]])\n",
        "\n",
        "        x_concat = tf.concat([x, skip], axis=-1)\n",
        "\n",
        "        x_resnet_1 = self.resnet_block(x_concat)\n",
        "        x_resnet_2 = self.resnet_block_2(x_resnet_1)\n",
        "\n",
        "        t = tf.keras.activations.silu(t)\n",
        "        t = self.linear(t)\n",
        "\n",
        "        t = tf.expand_dims(t, axis=1)\n",
        "        t = tf.expand_dims(t, axis=1)\n",
        "\n",
        "        t = tf.tile(t, [1, 8, 8, 1])\n",
        "        print(f\"x_resnet_2: {x_resnet_2.shape}\")\n",
        "        print(f\"t: {t.shape}\")\n",
        "        # Add t to x_resnet_2\n",
        "        x_resnet_2 = tf.image.resize(x_resnet_2, [t.shape[1], t.shape[2]])\n",
        "        return x_resnet_2 + t"
      ],
      "metadata": {
        "id": "oJmlKwd0aOer"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiffusionModel(tf.keras.Model):\n",
        "    def __init__(self, img_size=32, base_filters=64, time_embedding_dim=256):\n",
        "        super(DiffusionModel, self).__init__()\n",
        "        self.time_embedding = TimeEmbedding(time_embedding_dim)\n",
        "        self.first_resnet = ResNetBlock(base_filters * 8, 3)\n",
        "        self.init_conv = tf.keras.layers.Conv2D(base_filters, 3, padding='same')\n",
        "\n",
        "        self.down1 = DownSampleBlock(base_filters * 2, 3)\n",
        "        self.down2 = DownSampleBlock(base_filters * 4, 3)\n",
        "        self.down3 = DownSampleBlock(base_filters * 8, 3)\n",
        "\n",
        "        self.mid_resnet1 = ResNetBlock(base_filters * 8, 3)\n",
        "        self.mid_attention = SelfAttentionBlock(base_filters * 8)\n",
        "        self.mid_resnet2 = ResNetBlock(base_filters * 8, 3)\n",
        "\n",
        "        self.up1 = UpsampleBlock(base_filters * 4, 3)\n",
        "        self.up2 = UpsampleBlock(base_filters * 2, 3)\n",
        "        self.up3 = UpsampleBlock(base_filters, 3)\n",
        "\n",
        "        self.final_norm = tf.keras.layers.GroupNormalization(axis=-1)\n",
        "        self.final_conv = tf.keras.layers.Conv2D(3, 3, padding='same')\n",
        "\n",
        "    def call(self, x, timesteps):\n",
        "        t = self.time_embedding(timesteps)\n",
        "\n",
        "        x = self.init_conv(x)\n",
        "        x = self.first_resnet(x)\n",
        "        skip1 = x\n",
        "\n",
        "        x = self.down1([x, t])\n",
        "        skip2 = x\n",
        "\n",
        "        x = self.down2([x, t])\n",
        "        skip3 = x\n",
        "\n",
        "        x = self.down3([x, t])\n",
        "        x = self.mid_attention(x)\n",
        "        x = self.mid_resnet1(x)\n",
        "\n",
        "        x = self.up1([x, skip3, t])\n",
        "        x = self.up2([x, skip2, t])\n",
        "        x = self.up3([x, skip1, t])\n",
        "\n",
        "        x = self.final_norm(x)\n",
        "        x = self.final_conv(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ny3gZN5dF5oo"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DiffusionModel()\n",
        "batch_size = 4\n",
        "img = tf.random.normal((batch_size, 32, 32, 3))\n",
        "t = tf.random.uniform((batch_size,), maxval=1000, dtype=tf.int32)\n",
        "prediction = model(img, t)\n",
        "print(f\"Output shape: {prediction.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M3IS4DeLtPQ",
        "outputId": "11ee3784-d1c3-4446-e704-e25a6e7a5b53"
      },
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:1331: UserWarning: Layer 'down_sample_block_126' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
            "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
            "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
            "Exception encountered: ''Exception encountered when calling ResNetBlock.call().\n",
            "\n",
            "\u001b[1mUsing a symbolic `tf.Tensor` as a Python `bool` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\u001b[0m\n",
            "\n",
            "Arguments received by ResNetBlock.call():\n",
            "  • inputs=tf.Tensor(shape=(4, 16, 16, 512), dtype=float32)''\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'down_sample_block_126', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:1331: UserWarning: Layer 'down_sample_block_127' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
            "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
            "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
            "Exception encountered: ''Exception encountered when calling ResNetBlock.call().\n",
            "\n",
            "\u001b[1mUsing a symbolic `tf.Tensor` as a Python `bool` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\u001b[0m\n",
            "\n",
            "Arguments received by ResNetBlock.call():\n",
            "  • inputs=tf.Tensor(shape=(4, 8, 8, 128), dtype=float32)''\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'down_sample_block_127', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:1331: UserWarning: Layer 'down_sample_block_128' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
            "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
            "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
            "Exception encountered: ''Exception encountered when calling ResNetBlock.call().\n",
            "\n",
            "\u001b[1mUsing a symbolic `tf.Tensor` as a Python `bool` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\u001b[0m\n",
            "\n",
            "Arguments received by ResNetBlock.call():\n",
            "  • inputs=tf.Tensor(shape=(4, 4, 4, 256), dtype=float32)''\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'down_sample_block_128', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape after upsampling: (4, 2, 32, 512)\n",
            "skip shape after reduction: (4, 8, 8, 256)\n",
            "After resizing skip shape: (4, 2, 32, 256)\n",
            "x shape after upsampling: (4, 2, 32, 512)\n",
            "skip shape after reduction: (4, 8, 8, 256)\n",
            "After resizing skip shape: (4, 2, 32, 256)\n",
            "x_resnet_2: (4, 2, 32, 256)\n",
            "t: (4, 8, 8, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:1331: UserWarning: Layer 'upsample_block_126' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
            "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
            "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
            "Exception encountered: ''Exception encountered when calling ResNetBlock.call().\n",
            "\n",
            "\u001b[1mUsing a symbolic `tf.Tensor` as a Python `bool` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\u001b[0m\n",
            "\n",
            "Arguments received by ResNetBlock.call():\n",
            "  • inputs=tf.Tensor(shape=(4, 2, 32, 768), dtype=float32)''\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'upsample_block_126', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape after upsampling: (4, 16, 16, 256)\n",
            "skip shape after reduction: (4, 16, 16, 128)\n",
            "After resizing skip shape: (4, 16, 16, 128)\n",
            "x shape after upsampling: (4, 16, 16, 256)\n",
            "skip shape after reduction: (4, 16, 16, 128)\n",
            "After resizing skip shape: (4, 16, 16, 128)\n",
            "x_resnet_2: (4, 16, 16, 128)\n",
            "t: (4, 8, 8, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:1331: UserWarning: Layer 'upsample_block_127' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
            "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
            "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
            "Exception encountered: ''Exception encountered when calling ResNetBlock.call().\n",
            "\n",
            "\u001b[1mUsing a symbolic `tf.Tensor` as a Python `bool` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\u001b[0m\n",
            "\n",
            "Arguments received by ResNetBlock.call():\n",
            "  • inputs=tf.Tensor(shape=(4, 16, 16, 384), dtype=float32)''\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'upsample_block_127', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape after upsampling: (4, 16, 16, 128)\n",
            "skip shape after reduction: (4, 32, 32, 64)\n",
            "After resizing skip shape: (4, 16, 16, 64)\n",
            "x shape after upsampling: (4, 16, 16, 128)\n",
            "skip shape after reduction: (4, 32, 32, 64)\n",
            "After resizing skip shape: (4, 16, 16, 64)\n",
            "x_resnet_2: (4, 16, 16, 64)\n",
            "t: (4, 8, 8, 64)\n",
            "Output shape: (4, 8, 8, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:1331: UserWarning: Layer 'upsample_block_128' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
            "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
            "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
            "Exception encountered: ''Exception encountered when calling ResNetBlock.call().\n",
            "\n",
            "\u001b[1mUsing a symbolic `tf.Tensor` as a Python `bool` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\u001b[0m\n",
            "\n",
            "Arguments received by ResNetBlock.call():\n",
            "  • inputs=tf.Tensor(shape=(4, 16, 16, 192), dtype=float32)''\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'upsample_block_128', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4ilNh6XPJVri"
      },
      "execution_count": 296,
      "outputs": []
    }
  ]
}